##### 数据密集型应用
1. 软件千变万化，终有若干理念贯穿其中，本书着重探讨不同的设计理念以及如何权衡。
2. 本书主要分成三部分
   1. 主要讨论有关增强数据密集型应用系统所需的若干基本原则
      1. 可靠性、可扩张性、可维护性
      2. 多种不同数据模型与查询语言，讨论各自的适用场景
      3. 存储引擎，数据库如何安排磁盘结构，从而提高检索效率
      4. 数据序列化，常见模式的演变过程
   2. 从单机数据库存储转向跨机器的分布式系统
      1. 数据远程复制
      2. 数据分区
      3. 事务
      4. 分布式环境如何达成共识与一致性
   3. 产生派生数据的系统，主要只数据异构
      1. 批处理
      2. 流处理
      3. 总结之前介绍的技术，探讨未来构建可靠、可扩展、可维护应用系统可能的新方向或方法
3. 数据系统基础
   1. 可靠、可扩展与可维护的应用系统
      1. 可靠性：当出现意外情况如硬件、软件故障、人为失误等，系统应可以正常运转：虽然性能可能有所降低，但确保功能正确。
      2. 可扩展性：随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长
         1. 描述负载：qps、IO、CPU、缓存命中率、数据库写入比例
         2. 描述性能：响应时间（服务）、吞吐量（数据系统）
      3. 可维护性：随着时间的推移，许多新的人员参与到系统开发和运维，以维护现有功能或适配新场景等，系统都应高效运转
         1. 可运维性：运维更轻松
            1. 良好的可操作性意味着是日常工作更加简单
               * 提供对系统运行时，行为和内部的可观测性，方便监控
               * 支持自动化，与标准工具集成
               * 避免绑定特定机器，允许机器停机维护，保证系统不间断运行
               * 提供良好的文档和易于理解的操作模式，eg：如果我做了X会发生Y
               * 提供良好的默认配置，且允许管理员在需要时方便的修改默认值
               * 尝试自我修复，在需要时让管理员手动控制系统状态
               * 行为可预测，减少意外发生
         2. 简单性，简化复杂度
            * 复杂性有各种各样的表现形式：状态空间的膨胀、模块紧耦合、令人纠结的相互依赖关系、不一致的命名和术语、为了性能而采取的特殊处理、未解决特定问题而引入的特殊处理框架
            * 消除意外复杂性最好的手段之一是抽象
         3. 可演化性，易于改变
   2. 数据模型与查询语言
      1. 关系型数据模型
      2. 文档型数据模型
      3. 图状数据模型
   3. 数据存储与检索
      1. 数据库核心；数据结构
         * 索引：适当的索引可以加快检索的速度，但每个索引都会减慢写速度
           * Hash索引
             * 所有key都放在内存中，value保存数据存储的位置偏移量，这样value可以存储远大于内存的数据
             * 追加日志，每次k-v的变化，都追加到日志中
             * 日志分段，避免磁盘用尽，日志文件到达一定大小后就分段，然后在这些段上就可以执行压缩，即只保留每个键最近一次更新
             * 段合并，段压缩以后会变小，多个段可以合并成一个段，写入新的文件中。每个段都有自己的HashMap，按段的时间倒序检查key，段的压缩与合并在后台进行，结束后将旧文件删除，使用新文件
             * 需要考虑的问题
               * 文件格式，使用二进制格式，首先以字节为单位来记录字符串的长度，之后跟上原始字符串
               * 删除记录，如果要删除k-v，则必须在日志文件中追加一个特殊记录（有事成为墓碑），当日志段合并时，当发现墓碑标记则会丢弃这个键的所有值
               * 崩溃恢复，读取段重新加载k-v，如果日志段太大可能会耗费太长时间，可以每隔一段时间做快照，通过快照来恢复
               * 部分写入的记录
               * 并发控制，写的时候是以严格的先后顺序写入，通常只用一个线程写入，数据文件段是追加的，并且是不可变的，所以他们可以被多个线程同时读取
             * 局限性
               * Hash表必须全部放入内存，如果有大量的键，存储在磁盘上，存在大量的io，hash变满，继续增长代价昂贵，hash冲突时，需要复杂的处理逻辑
               * 对区间查找不友好
           * SSTables和LSM-TREE(es)
             * 要求k-v对的顺序按键排序，这种格式成为排序字符串表，或简称为SSTables
             * SSTables相较于Hash索引的优点
               * 合并段更加高效，即使文件大于可用内存。方法类似于归并排序算法中使用方法。如果相同键出现在多个输入段怎么办？每个段包含在某段时间内写入数据库的所有值。当多个段包含相同键时，可以保留最新段的值，并丢弃旧段中的值
               * 在文件中查找特定键时，不再需要在内存中保存所有键的索引。不过仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的。有序的键，保证在找到离目标键最近的索引记录后，可以从段中查找
               * 由于读请求往往需要扫描请求范围内的多个k-v对，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩。然后稀疏内存索引的每个条目指向压缩块开头，除了节省磁盘空间，压缩还减少了I/O带宽的占用
             * 构建和维护SSTables
               1. 当写入时，将其添加到内存中平衡树数据结构中（红黑树）。这个内存中的树有时被称为内存表
               2. 当内存表大于某个阈值时，将其作为SSTables文件写入磁盘，由于树已经维护了有序的k-v，写磁盘可以比较高效，新的table成为数据库的最新部分，当table写磁盘时，可以添加到一个新的内存表实例
               3. 为了处理读请求，先在内存表中查找键，然后是最新的磁盘段文件，接着次新，以此类推，直到找到目标
               4. 后台进程周期性的压缩合并，并丢弃那些被覆盖或删除的值
               5. 为了防止数据库崩溃数据丢失，将每个操作写入日志，日志不需要保持key的顺序。每当将SStables写入磁盘后，相应的日志可以被丢弃
             * 从SSTables到LSM-TREE（Log-Structured Merge-Tree），基于合并和压缩排序文件原理存储引擎通常都被成为LSM存储引擎
             * 性能优化
               * 当要查询的键不存在时，LSM-Tree算法可能很慢，需要遍历内存表、所有的段才能确定，使用布隆过滤器
           * B-Tree：将数据库分解成固定大小的块或页
             * 预写日志-WAL（write ahead log），仅支持追加修改的文件，每个B-Tree都需要先写日志，再修改树本身的页
             * 多线程访问B-Tree，需要注意并发控制，否则线程可能看到树处于不一致的状态。通常使用锁存器保护树的数据结构。日志结构化的方式比较简单，因为他们在后台执行所有合并，而不会干扰前端的查询，并且会不时地用新段原子的替换旧段。
           * 对比B-Tree与LSM-Tree
             * 根据经验，LSM通常写入更快，而B被认为读取更快。因为LSM在读取阶段，必须检查在不同压缩阶段的多个不同的数据结构与SSTable
           * LSM-Tree的优点
             * LSM 通常能够承受比B树更高的写入吞吐量，部分是因为他们有时具有较低的写放大，部分原因是他们以顺序将紧凑的SSTable写入磁盘，而不必重写树中的多个页
             * LSM可以更好的支持压缩，通常磁盘上的文件比B树小。由于碎片，B树上的有些空间无法利用：当页被分裂或当一行的内容不能适合现有页时。
           * LSM-Tree的缺点
             * 压缩过程有时会干扰正在进行的读写操作。B-Tree的响应延迟更具确定性
             * 高写入吞吐量时，磁盘的有限写入带宽，需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间共享。有时后台合并任务会没有资源进行，导致段文件越来越多，直到磁盘空间耗尽，同时查询也会受到影响，需要检查更多的段文件。需要增加监控措施
             * B-tree优点是每个键都恰好对应于索引中唯一位置；而日志结构的索引，可能在不同的段中具有相同键的多个副本。如果数据库希望提供强大的事务语义，B-Tree更具吸引力
         * 其他索引结构
           * 二级索引
           * 聚簇索引
           * 多列索引：级联索引
         * 全文搜索和模糊索引
         * 在内存中保存所有内容
           * 内存数据库可以更快是因为他们避免使用写磁盘的格式对内存数据结构编码的开销
           * 内存数据库另一个有意思的地方是，它提供了基于磁盘索引难以实现的某些数据模型。例如redis的各种数据结构（如优先级队列与集合）
           * 内存数据库架构可以扩展到支持远大于内存的数据集，而不会导致以磁盘为中心架构的开销。使用LRU,数据交换。不过仍需将所有索引放入缓存中
      2. 事务处理（OLTP）与分析处理（OLAP）
         * 主要特性对比 
           * |属性|OLTP|OLAP|
              |--|--|--|
              |主要读特征|基于键，每次读返回少量数据|对大量记录进行汇总|
              |主要写特征|随机访问，低延迟写入用户的输入|批量导入（etl）或事件流|
              |典型使用场景|终端用户，通过网络应用程序|内部分析师，为决策提供支持|
              |数据表现|最新的数据状态（当前时间点）|随着时间变化而变化的所有事件历史|
              |数据规模|GB到TB|TB到PB|
         * 数据仓库
         * 星型与雪花型分析模式
           * 事实表：每一行表示在特定时间发生的事件，事实表中列式属性，可能引用其他表的外键，称为维度表，维度通常代表事件的who、what、where、when、how、why
           * 维度表
      * 列式存储
        * 不将一行中的所有值存储在一起，而是将每列中的所有值存储在一起，如果每个列单独存储在一个文件中，查询只需要读取在该查询中使用的那些列
        * 面向列的存储布局依赖一组列文件，每个文件以相同的顺序保存着数据行
        * 列压缩
          * 除了仅从磁盘中加载查询所需列外，还可以通过压缩数据进一步降低对磁盘吞吐量的要求
          * 位图编码：主要用于枚举值远小于行数的列。通常列中不同值的数量小于行数。现在可以使用n个不同值的列，并将其转换为n个单独的位图，一个位图对应每个不同的值，一个位对应一行。如果该行具有该值，该位为1否则为0
            * 如果枚举值特别少，可以使用游程编码
            * ![位图编码](位图编码.png)
        * 内存带宽和矢量化处理
        * 列存储中的排序，单独列的排序是没有意义的
        * 列存储的写操作，LSM-TREE
        * 聚合：数据立方体和物化视图
          * 数据仓库查询通常涉及聚合函数，如果许多不同查询使用相同的聚合，每次处理原始数据都非常浪费资源。物化视图是查询结果的副本，并被写到磁盘，当底层数据发生变化时，物化视图也需要随之变更
   4. 数据编码与演化
      1. 数据编码格式
         * 程序通常使用（至少）两种不同的数据表现形式
           * 在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对CPU的高效访问与操作做了针对性优化
           * 将数据写入文件或通过网络发送时，必须将其编码为某种只包含的字节序列。由于指针对其他进程没有意义，所以这个字节序列与在内存中保存的数据结构不太一样
         * JSON与XML
           * 文本格式，具有不错的可读性
           * 数字编码有模糊之处。字符串与数字、整数与浮点数的区分、浮点数精度
           * 不支持二进制字符串，需要想用Base64编码，数据大小增加了33%
           * 需要有模式支持
         * 二进制编码
         * Thrift与Protocol Buffers
           * 需要模式来编码任意的数据，模式可以理解为java中的类
           * 使用字段标签来标识字段名称，相当于别名
           * Thrift CompactProtocol 编码语义上 同于 Binary Protocol ，将字段类型和标签号打包到单字节中，并使用可
             变长度整数来实现。对数字1337，不使用全部8字节，而是使用两个字节进行编码，每字节的最高位用来指示是否还有更多的字节，意味着-64~63 之间的数字被编码
             一字节， -8192~8191 之 间的数字被编码成两个字节等。 更大的数字需要更多字节。
           * 字段标签和模式演化（向前兼容与向后兼容）
             * 向后兼容可以新增非必填的字段，删除非必填的字段
             * 向前兼容，只能删除非必填字段，不能再使用相同的标签号码
         * Avro
           * Hadoop子项目
           * 编码只是由连在一起的一些列值组成。一个字符串只是一个长度前缀，后跟UTF-8字节流，但编码数据中没有任何内容告诉你他是一个字符串。它也可以是一个整数，或者其他什么类型。整数使用可变长度进行编码。为了解析二进制值数据，按照他们出现在模式中的顺序遍历这些字段，然后直接采用模式告诉每个字段的数据类型。这意味着只有当读取数据代码使用与写入数据的代码完全相同的模式时，才能正确解码二进制数据。
           * 写模式与读模式
             * 写模式：当应用程序想要对某些数据进行编码时，它使用所知道的模式的任何版本来编码数据。
             * 读模式：当应用程序想要解码某些数据时，它期望数据符合某个模式
             * 读模式与写模式不必完全相同，他们只需保持兼容。当数据被解码时，Avro库通过对比插卡读写模式，并将数据从写模式转化成读模式来解决差异。具体可查看Arvo规范。eg：若读模式与写模式的字段顺序不同，模式解析通过字段名匹配字段，如果读模式中不存在则忽略，如果写模式不存在则使用默认值
           * 模式演化规则
             * 向前兼容意味着可以将新版本的模式作为writer，旧版本的模式作为reader；相反向后兼容意味着可以将旧版本的模式作为writer，新版本模式作为reader
             * 为了保持兼容只能添加或删除有默认值的字段
             * writer模式是什么
               * reader如何知道特定的数据采用哪个writer模式编码？在每个记录中包含整个模式不太现实，因为模式有时比编码数据还要大的多，这样二进制编码所节省的空间就没有意义
               * 取决于Arvo使用的上下文
                 * 有很多记录的大文件，写入文件时记录模式版本
                 * 具有单独写入记录的数据库，有一个表记录模式版本，并在数据记录中引用
                 * 通过网络连接发送记录，当两个进程通过双向网络连接进行通信时，在建立连接时协商模式版本
           * 动态生成的模式
             * Arvo 不包含任何标签号，像protocol buffer 跟Thrift 在新增字段与删除字段时标签号可能需要手动新增
         * 模式的优点
           * 他们可以比各种”二进制Json“的变体更紧凑，可以省略编码数据中的字段名称
           * 模式是一种有价值的文档格式，因为模式是解码必须的，所以可以确定他是最新的（而手动维护的文档可能很容易偏离现实）
           * 模式数据库允许在部署任何内容之前检查模式更改的向前向后兼容性
           * 对于静态类型编程语言用户来说，从模式生成代码的能力是有用的，它能够在编译时进行类型检查
      2. 数据流模式